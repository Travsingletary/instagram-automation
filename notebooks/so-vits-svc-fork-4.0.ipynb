{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7yjzcji963s"
      },
      "source": [
        "## Before training\n",
        "\n",
        "This program saves the last 3 generations of models to Google Drive. Since 1 generation of models is >1GB, you should have at least 3GB of free space in Google Drive. If you do not have such free space, it is recommended to create another Google Account.\n",
        "\n",
        "Training requires >10GB VRAM. (T4 should be enough) Inference does not require such a lot of VRAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDvHstim963t"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OTJahOFk963t",
        "outputId": "0f75a549-bca0-4af2-ee89-5b5455de0800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 26 03:01:27 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# @title Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FdEDIY-2963t",
        "outputId": "84d1f7ee-e998-41ec-c0f1-c06b2e585a52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M6Aab9Hm963t",
        "outputId": "2d82b3bb-8ec7-450e-f743-189966647c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (7.34.0)\n",
            "Collecting ipython\n",
            "  Downloading ipython-9.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython) (4.4.2)\n",
            "Collecting ipython-pygments-lexers (from ipython)\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from ipython) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from ipython) (2.19.2)\n",
            "Collecting stack_data (from ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from ipython)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Collecting executing>=1.2.0 (from stack_data->ipython)\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->ipython)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->ipython)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipython-9.5.0-py3-none-any.whl (612 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.4/612.4 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pure-eval, traitlets, jedi, ipython-pygments-lexers, executing, asttokens, stack_data, ipython\n",
            "\u001b[2K  Attempting uninstall: traitlets\n",
            "\u001b[2K    Found existing installation: traitlets 5.7.1\n",
            "\u001b[2K    Uninstalling traitlets-5.7.1:\n",
            "\u001b[2K      Successfully uninstalled traitlets-5.7.1\n",
            "\u001b[2K  Attempting uninstall: ipython\n",
            "\u001b[2K    Found existing installation: ipython 7.34.0\n",
            "\u001b[2K    Uninstalling ipython-7.34.0:\n",
            "\u001b[2K      Successfully uninstalled ipython-7.34.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [ipython]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-3.0.0 executing-2.2.1 ipython-9.5.0 ipython-pygments-lexers-1.1.1 jedi-0.19.2 pure-eval-0.2.3 stack_data-0.6.3 traitlets-5.14.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "traitlets"
                ]
              },
              "id": "60a58c56180346d987011c66aaf0a5fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting so-vits-svc-fork\n",
            "  Downloading so_vits_svc_fork-4.2.27-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from so-vits-svc-fork) (8.2.1)\n",
            "Collecting cm-time>=0.1.2 (from so-vits-svc-fork)\n",
            "  Downloading cm_time-0.1.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: fastapi>=0.116.1 in /usr/local/lib/python3.12/dist-packages (from so-vits-svc-fork) (0.116.2)\n",
            "Requirement already satisfied: librosa>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from so-vits-svc-fork) (0.11.0)\n",
            "Collecting lightning>=2.5.5 (from so-vits-svc-fork)\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: matplotlib>=3.9.4 in /usr/local/lib/python3.12/dist-packages (from so-vits-svc-fork) (3.10.0)\n",
            "Requirement already satisfied: numpy>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from so-vits-svc-fork) (2.0.2)\n",
            "Collecting pebble>=5.1.3 (from so-vits-svc-fork)\n",
            "  Downloading Pebble-5.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting praat-parselmouth>=0.4.6 (from so-vits-svc-fork)\n",
            "  Downloading praat_parselmouth-0.4.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting pysimplegui-4-foss>=4.60.4.1 (from so-vits-svc-fork)\n",
            "  Downloading PySimpleGUI_4_foss-4.60.4.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyworld>=0.3.5 (from so-vits-svc-fork)\n",
            "  Downloading pyworld-0.3.5.tar.gz (261 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "# @title Install dependencies\n",
        "# @markdown pip may fail to resolve dependencies and raise ERROR, but it can be ignored.\n",
        "!python -m pip install -U pip wheel\n",
        "%pip install -U ipython\n",
        "\n",
        "# @markdown Branch (for development)\n",
        "BRANCH = \"none\"  # @param {\"type\": \"string\"}\n",
        "if BRANCH == \"none\":\n",
        "    %pip install -U so-vits-svc-fork\n",
        "else:\n",
        "    %pip install -U git+https://github.com/34j/so-vits-svc-fork.git@{BRANCH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GDX103G963t"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDnrZjy7963t"
      },
      "outputs": [],
      "source": [
        "# @title Make dataset directory\n",
        "!mkdir -p \"dataset_raw\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDIdliaa963t"
      },
      "outputs": [],
      "source": [
        "#!rm -r \"dataset_raw\"\n",
        "#!rm -r \"dataset/44k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H1CChvv963t"
      },
      "outputs": [],
      "source": [
        "# @title Copy your dataset\n",
        "# @markdown **We assume that your dataset is in your Google Drive's `so-vits-svc-fork/dataset/(speaker_name)` directory.**\n",
        "DATASET_NAME = \"kiritan\"  # @param {type: \"string\"}\n",
        "!cp -R /content/drive/MyDrive/so-vits-svc-fork/dataset/{DATASET_NAME}/ -t \"dataset_raw/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4uEkydz963t"
      },
      "outputs": [],
      "source": [
        "# @title Download dataset (Tsukuyomi-chan JVS)\n",
        "# @markdown You can download this dataset if you don't have your own dataset.\n",
        "# @markdown Make sure you agree to the license when using this dataset.\n",
        "# @markdown https://tyc.rei-yumesaki.net/material/corpus/#toc6\n",
        "# !wget https://tyc.rei-yumesaki.net/files/sozai-tyc-corpus1.zip\n",
        "# !unzip sozai-tyc-corpus1.zip\n",
        "# !mv \"/content/つくよみちゃんコーパス Vol.1 声優統計コーパス（JVSコーパス準拠）/おまけ：WAV（+12dB増幅＆高音域削減）/WAV（+12dB増幅＆高音域削減）\" \"dataset_raw/tsukuyomi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgPLocD0963u"
      },
      "outputs": [],
      "source": [
        "# @title Automatic preprocessing\n",
        "!svc pre-resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_gL8Can963u"
      },
      "outputs": [],
      "source": [
        "!svc pre-config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_J_37pA963u"
      },
      "outputs": [],
      "source": [
        "# @title Export configs file\n",
        "# @markdown This assumes that you want to save the **config.json** on the default location. There will be also a backup file created in case the action is done accidentally.!cp configs/44k/config.json configs/44k/config.bkp.json!cp drive/MyDrive/so-vits-svc-fork/config.json configs/44k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvkrrX3-963u"
      },
      "outputs": [],
      "source": [
        "# @title Import configs file (Optional Step, NOT REQUIRED)\n",
        "# @markdown This assumes that you are saving the **config.json** on the default location. There will be also a backup file created in case the action is done accidentally.!cp drive/MyDrive/so-vits-svc-fork/config.json drive/MyDrive/so-vits-svc-fork/config.bkp.json!cp configs/44k/config.json drive/MyDrive/so-vits-svc-fork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGdOHWRx963u"
      },
      "outputs": [],
      "source": [
        "F0_METHOD = \"dio\"  # @param [\"crepe\", \"crepe-tiny\", \"parselmouth\", \"dio\", \"harvest\"]\n",
        "!svc pre-hubert -fm {F0_METHOD}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IKOev4P963u"
      },
      "outputs": [],
      "source": [
        "# @title Train\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir drive/MyDrive/so-vits-svc-fork/logs/44k\n",
        "!svc train --model-path drive/MyDrive/so-vits-svc-fork/logs/44k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzeKVc5I963u"
      },
      "source": [
        "## Training Cluster model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-CFH9O7963u"
      },
      "outputs": [],
      "source": [
        "!svc train-cluster --output-path drive/MyDrive/so-vits-svc-fork/logs/44k/kmeans.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNWjRm0S963u"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQDN2Z6x963u"
      },
      "outputs": [],
      "source": [
        "# @title Get the author's voice as a source\n",
        "import random\n",
        "\n",
        "NAME = str(random.randint(1, 49))\n",
        "TYPE = \"fsd50k\"  # @param [\"\", \"digit\", \"dog\", \"fsd50k\"]\n",
        "CUSTOM_FILEPATH = \"\"  # @param {type: \"string\"}\n",
        "if CUSTOM_FILEPATH != \"\":\n",
        "    NAME = CUSTOM_FILEPATH\n",
        "else:\n",
        "    # it is extremely difficult to find a voice that can download from the internet directly\n",
        "    if TYPE == \"dog\":\n",
        "        !wget -N f\"https://huggingface.co/datasets/437aewuh/dog-dataset/resolve/main/dogs/dogs_{NAME:.0000}.wav\" -O {NAME}.wav\n",
        "    elif TYPE == \"digit\":\n",
        "        # george, jackson, lucas, nicolas, ...\n",
        "        !wget -N f\"https://github.com/Jakobovski/free-spoken-digit-dataset/raw/master/recordings/0_george_{NAME}.wav\" -O {NAME}.wav\n",
        "    elif TYPE == \"fsd50k\":\n",
        "        !wget -N f\"https://huggingface.co/datasets/Fhrozen/FSD50k/blob/main/clips/dev/{10000+int(NAME)}.wav\" -O {NAME}.wav\n",
        "    else:\n",
        "        !wget -N f\"https://zunko.jp/sozai/utau/voice_{\"kiritan\" if NAME < 25 else \"itako\"}{NAME % 5 + 1}.wav\" -O {NAME}.wav\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "display(Audio(f\"{NAME}.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIJpvx6b963u"
      },
      "outputs": [],
      "source": [
        "# @title Use trained model\n",
        "# @markdown **Put your .wav file in `so-vits-svc-fork/audio` directory**\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "!svc infer drive/MyDrive/so-vits-svc-fork/audio/{NAME}.wav -m drive/MyDrive/so-vits-svc-fork/logs/44k/ -c drive/MyDrive/so-vits-svc-fork/logs/44k/config.json\n",
        "display(Audio(f\"drive/MyDrive/so-vits-svc-fork/audio/{NAME}.out.wav\", autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShRZ0Wcs963u"
      },
      "outputs": [],
      "source": [
        "##@title Use trained model (with cluster)\n",
        "!svc infer {NAME}.wav -s speaker -r 0.1 -m drive/MyDrive/so-vits-svc-fork/logs/44k/ -c drive/MyDrive/so-vits-svc-fork/logs/44k/config.json -k drive/MyDrive/so-vits-svc-fork/logs/44k/kmeans.pt\n",
        "display(Audio(f\"{NAME}.out.wav\", autoplay=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIQB2SMv963u"
      },
      "source": [
        "### Pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoQ7ZbzL963u"
      },
      "outputs": [],
      "source": [
        "# @title https://huggingface.co/TachibanaKimika/so-vits-svc-4.0-models/tree/main\n",
        "!wget -N \"https://huggingface.co/TachibanaKimika/so-vits-svc-4.0-models/resolve/main/riri/G_riri_220.pth\"\n",
        "!wget -N \"https://huggingface.co/TachibanaKimika/so-vits-svc-4.0-models/resolve/main/riri/config.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbGbW9AF963u"
      },
      "outputs": [],
      "source": [
        "!svc infer {NAME}.wav -c config.json -m G_riri_220.pth\n",
        "display(Audio(f\"{NAME}.out.wav\", autoplay=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgq8da4l963u"
      },
      "outputs": [],
      "source": [
        "# @title https://huggingface.co/therealvul/so-vits-svc-4.0/tree/main\n",
        "!wget -N \"https://huggingface.co/therealvul/so-vits-svc-4.0/resolve/main/Pinkie%20(speaking%20sep)/G_166400.pth\"\n",
        "!wget -N \"https://huggingface.co/therealvul/so-vits-svc-4.0/resolve/main/Pinkie%20(speaking%20sep)/config.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IBqI8Zj963u"
      },
      "outputs": [],
      "source": [
        "!svc infer {NAME}.wav --speaker \"Pinkie {neutral}\" -c config.json -m G_166400.pth\n",
        "display(Audio(f\"{NAME}.out.wav\", autoplay=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}